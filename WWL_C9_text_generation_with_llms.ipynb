{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/Working_with_Large_Language_models/blob/main/WWL_C9_text_generation_with_llms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySlLZ-fLrffg"
      },
      "source": [
        "# Text Generation with Open-Source LLMs\n",
        "\n",
        "This notebook demonstrates how to use several popular open-source Large Language Models (LLMs) to generate text. We will cover the following models:\n",
        "\n",
        "1. **GPT-2** by OpenAI\n",
        "2. **GPT-Neo** by EleutherAI\n",
        "3. **BLOOM** by BigScience\n",
        "4. **StableLM** by Stability AI\n"
      ],
      "id": "ySlLZ-fLrffg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC0unap3rffh"
      },
      "source": [
        "## 1. GPT-2\n",
        "\n",
        "**Model Source:** OpenAI\n",
        "\n",
        "**Model Type:** Transformer-based Language Model\n",
        "\n",
        "**Description:** GPT-2 is a large transformer-based language model trained on a diverse dataset of internet text. It can generate coherent and contextually relevant text based on a given prompt."
      ],
      "id": "GC0unap3rffh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymLV6s3Urffi"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, set_seed\n",
        "\n",
        "def generate_text_with_gpt2(prompt, max_length=50, num_return_sequences=1, seed=42):\n",
        "    generator = pipeline('text-generation', model='gpt2')\n",
        "    set_seed(seed)\n",
        "    outputs = generator(prompt, max_length=max_length, num_return_sequences=num_return_sequences)\n",
        "    return outputs\n",
        "\n",
        "# Example usage\n",
        "prompt = \"Once upon a time\"\n",
        "print(\"GPT-2 Output:\")\n",
        "print(generate_text_with_gpt2(prompt))"
      ],
      "id": "ymLV6s3Urffi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYygGQdYrffi"
      },
      "source": [
        "## 2. GPT-Neo\n",
        "\n",
        "**Model Source:** EleutherAI\n",
        "\n",
        "**Model Type:** Transformer-based Language Model\n",
        "\n",
        "**Description:** GPT-Neo is an open-source equivalent to OpenAI's GPT-3. It is designed to be a large-scale language model capable of generating high-quality text."
      ],
      "id": "uYygGQdYrffi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BATQWizGrffj"
      },
      "outputs": [],
      "source": [
        "def generate_text_with_gpt3(prompt, max_length=50, num_return_sequences=1, seed=42):\n",
        "    generator = pipeline('text-generation', model='EleutherAI/gpt-neo-2.7B')\n",
        "    set_seed(seed)\n",
        "    outputs = generator(prompt, max_length=max_length, num_return_sequences=num_return_sequences)\n",
        "    return outputs\n",
        "\n",
        "# Example usage\n",
        "print(\"\\nGPT-Neo Output:\")\n",
        "print(generate_text_with_gpt3(prompt))"
      ],
      "id": "BATQWizGrffj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQFhhGamrffj"
      },
      "source": [
        "## 3. BLOOM\n",
        "\n",
        "**Model Source:** BigScience\n",
        "\n",
        "**Model Type:** Transformer-based Language Model\n",
        "\n",
        "**Description:** BLOOM is a large language model developed by the BigScience project. It aims to provide an open and accessible large-scale language model for research and practical applications."
      ],
      "id": "eQFhhGamrffj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0zrX6o-rffj"
      },
      "outputs": [],
      "source": [
        "def generate_text_with_bloom(prompt, max_length=50, num_return_sequences=1, seed=42):\n",
        "    generator = pipeline('text-generation', model='bigscience/bloom-560m')\n",
        "    set_seed(seed)\n",
        "    outputs = generator(prompt, max_length=max_length, num_return_sequences=num_return_sequences)\n",
        "    return outputs\n",
        "\n",
        "# Example usage\n",
        "print(\"\\nBLOOM Output:\")\n",
        "print(generate_text_with_bloom(prompt))"
      ],
      "id": "J0zrX6o-rffj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3osl5Berffj"
      },
      "source": [
        "## 4. StableLM\n",
        "\n",
        "**Model Source:** Stability AI\n",
        "\n",
        "**Model Type:** Transformer-based Language Model\n",
        "\n",
        "**Description:** StableLM is an open-source language model developed by Stability AI, designed to generate text with high coherence and relevance."
      ],
      "id": "P3osl5Berffj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YM23Rqrrffj"
      },
      "outputs": [],
      "source": [
        "def generate_text_with_stablelm(prompt, max_length=50, num_return_sequences=1, seed=42):\n",
        "    generator = pipeline('text-generation', model='StabilityAI/stablelm-base-alpha-3b')\n",
        "    set_seed(seed)\n",
        "    outputs = generator(prompt, max_length=max_length, num_return_sequences=num_return_sequences)\n",
        "    return outputs\n",
        "\n",
        "# Example usage\n",
        "print(\"\\nStableLM Output:\")\n",
        "print(generate_text_with_stablelm(prompt))"
      ],
      "id": "7YM23Rqrrffj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u1Xk0vErffj"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we demonstrated how to use various open-source LLMs to generate text. Each model has unique characteristics and can be chosen based on specific requirements for text generation tasks."
      ],
      "id": "7u1Xk0vErffj"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}