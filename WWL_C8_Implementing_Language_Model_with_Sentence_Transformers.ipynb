{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/Working_with_Large_Language_models/blob/main/WWL_C8_Implementing_Language_Model_with_Sentence_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9edd65b0",
      "metadata": {
        "id": "9edd65b0"
      },
      "source": [
        "# Exercise: Implementing a Language Model Using Sentence Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0b6dfac",
      "metadata": {
        "id": "a0b6dfac"
      },
      "source": [
        "\n",
        "In this notebook, we will walk through the process of implementing a language model using Sentence Transformers. Sentence Transformers is a framework for sentence, paragraph, and image embeddings using BERT-like models. This framework makes it easy to generate embeddings for sentences and paragraphs which can then be used in various NLP tasks such as semantic search, clustering, and classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df9102c1",
      "metadata": {
        "id": "df9102c1"
      },
      "source": [
        "\n",
        "## Prerequisites\n",
        "\n",
        "Before we start, make sure you have Python installed on your machine. You will also need to install the following packages:\n",
        "\n",
        "```bash\n",
        "pip install sentence-transformers\n",
        "pip install numpy\n",
        "pip install torch\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJMOj-yX90Oi",
        "outputId": "a3379157-94ed-44a1-a295-ca5ae88b762f"
      },
      "id": "pJMOj-yX90Oi",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2344425",
      "metadata": {
        "id": "c2344425"
      },
      "source": [
        "## Step 1: Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2a6ac84f",
      "metadata": {
        "id": "2a6ac84f"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models,layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97ee1cb1",
      "metadata": {
        "id": "97ee1cb1"
      },
      "source": [
        "## Step 2: Loading the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "2a76bc8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a76bc8b",
        "outputId": "9e9c3294-42aa-4ec5-c76d-2d910f87d8e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load a pre-trained Sentence Transformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ec8bd5a",
      "metadata": {
        "id": "3ec8bd5a"
      },
      "source": [
        "## Step 3: Encoding Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f2a89f82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2a89f82",
        "outputId": "fd3fe08e-d770-41b2-fd51-d477476014df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: This is an example sentence.\n",
            "Embedding: [0.0981246  0.0678127  0.06252313 0.09508476 0.03664764]...\n",
            "\n",
            "Sentence: Each sentence is converted into a fixed-size vector.\n",
            "Embedding: [0.07381859 0.05663022 0.02722435 0.02096546 0.03240977]...\n",
            "\n",
            "Sentence: Sentence transformers are useful for various NLP tasks.\n",
            "Embedding: [-0.05859482  0.0160087   0.05453373  0.03032776  0.02576445]...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Example sentences\n",
        "sentences = [\n",
        "    \"This is an example sentence.\",\n",
        "    \"Each sentence is converted into a fixed-size vector.\",\n",
        "    \"Sentence transformers are useful for various NLP tasks.\"\n",
        "]\n",
        "\n",
        "# Encode the sentences into embeddings\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "# Display the embeddings\n",
        "for sentence, embedding in zip(sentences, embeddings):\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Embedding: {embedding[:5]}...\")  # Displaying first 5 dimensions for brevity\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e23904b0",
      "metadata": {
        "id": "e23904b0"
      },
      "source": [
        "## Step 4: Finding Similar Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "39302e0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39302e0b",
        "outputId": "a5c7d408-8d58-459d-c8bd-4e96b2e6db6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: This is an example sentence.\n",
            "Similarity Score: 0.3304\n",
            "\n",
            "Sentence: Each sentence is converted into a fixed-size vector.\n",
            "Similarity Score: 0.5168\n",
            "\n",
            "Sentence: Sentence transformers are useful for various NLP tasks.\n",
            "Similarity Score: 0.5501\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define a query sentence\n",
        "query_sentence = \"How are sentence embeddings generated?\"\n",
        "\n",
        "# Encode the query sentence\n",
        "query_embedding = model.encode(query_sentence)\n",
        "\n",
        "# Compute cosine similarity between the query sentence and the other sentences\n",
        "cosine_scores = util.pytorch_cos_sim(query_embedding, embeddings)\n",
        "\n",
        "# Display the results\n",
        "for sentence, score in zip(sentences, cosine_scores[0]):\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Similarity Score: {score.item():.4f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8c92b5a",
      "metadata": {
        "id": "b8c92b5a"
      },
      "source": [
        "## Step 5: Clustering Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "824a70ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "824a70ec",
        "outputId": "6c211447-18f7-4ed9-eb8e-6cc576896ac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 0:\n",
            "  - Each sentence is converted into a fixed-size vector.\n",
            "  - Sentence transformers are useful for various NLP tasks.\n",
            "\n",
            "Cluster 1:\n",
            "  - This is an example sentence.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Define the number of clusters\n",
        "num_clusters = 2\n",
        "\n",
        "# Perform K-Means clustering\n",
        "clustering_model = KMeans(n_clusters=num_clusters)\n",
        "clustering_model.fit(embeddings)\n",
        "cluster_assignment = clustering_model.labels_\n",
        "\n",
        "# Display the clustering results\n",
        "for i in range(num_clusters):\n",
        "    print(f\"Cluster {i}:\")\n",
        "    cluster_sentences = [sentences[j] for j in range(len(sentences)) if cluster_assignment[j] == i]\n",
        "    for sentence in cluster_sentences:\n",
        "        print(f\"  - {sentence}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0goiEYdOAPTW"
      },
      "id": "0goiEYdOAPTW",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19b9ff60"
      },
      "source": [
        "## Step 6: Define a TensorFlow Function for Sentence Embeddings"
      ],
      "id": "19b9ff60"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "c8c5b990"
      },
      "outputs": [],
      "source": [
        "# Define a TensorFlow function that uses the Sentence Transformer to get embeddings\n",
        "def sentence_embedding(sentence):\n",
        "    embedding = model.encode(sentence)\n",
        "    return tf.constant(embedding, dtype=tf.float32)\n"
      ],
      "id": "c8c5b990"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "278e1a79"
      },
      "source": [
        "## Step 7: Build LSTM Model"
      ],
      "id": "278e1a79"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "61de50d8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to build an LSTM model\n",
        "def build_model(vocab_size, embedding_dim, lstm_units):\n",
        "    language_model = models.Sequential([\n",
        "        layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True),\n",
        "        layers.LSTM(lstm_units, return_sequences=True),\n",
        "        layers.LSTM(lstm_units),\n",
        "        layers.Dense(vocab_size, activation='softmax')\n",
        "    ])\n",
        "    language_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return language_model\n"
      ],
      "id": "61de50d8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "989ef8e2"
      },
      "source": [
        "## Step 8: Prepare the Data"
      ],
      "id": "989ef8e2"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ad3a2223"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Example data preprocessing (assuming you have a dataset of sentences)\n",
        "sentences = [\"This is an example sentence.\", \"Sentence transformers are useful.\", \"This is another sentence.\"]\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Padding sequences to the same length\n",
        "max_length = max(len(seq) for seq in sequences)\n",
        "sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Split data into inputs and labels\n",
        "X, y = sequences[:, :-1], sequences[:, -1]\n"
      ],
      "id": "ad3a2223"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbde62a7"
      },
      "source": [
        "## Step 6: Train the Model"
      ],
      "id": "fbde62a7"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "e7e73b5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0713d6d3-63ab-48b2-ed67-1cc7dfeb491c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f8a4e3e5150>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "\n",
        "embedding_dim = 128\n",
        "lstm_units = 128\n",
        "\n",
        "language_model = build_model(vocab_size, embedding_dim, lstm_units)\n",
        "language_model.fit(X, y, epochs=10, batch_size=2,verbose=False)\n"
      ],
      "id": "e7e73b5e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1623b7d"
      },
      "source": [
        "## Step 7: Predict Next Word"
      ],
      "id": "a1623b7d"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "c1b354ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52dde221-31f4-4431-f2e7-0afa3aba8cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5851038  0.1786701  0.02727927 0.03728561 0.03317305 0.0246282\n",
            "  0.03144044 0.02969067 0.02466745 0.0280614 ]]\n",
            "0\n",
            "Next word prediction: sentence\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Function to predict the next word given a model, tokenizer, and sentence\n",
        "def predict_next_word(language_model, tokenizer, sentence, max_length):\n",
        "    embedding = sentence_embedding(sentence)\n",
        "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    tokenized_sentence = tf.keras.preprocessing.sequence.pad_sequences([tokenized_sentence], maxlen=max_length-1, padding='post')\n",
        "    prediction = language_model.predict(tokenized_sentence, verbose=0)\n",
        "    print(prediction)\n",
        "    predicted_word_index = np.argmax(prediction[0])\n",
        "    print(predicted_word_index)\n",
        "    predicted_word = tokenizer.index_word[predicted_word_index+1]\n",
        "    return predicted_word\n",
        "\n",
        "# Example prediction\n",
        "sentence = \"This is an example\"\n",
        "predicted_word = predict_next_word(language_model, tokenizer, sentence, max_length)\n",
        "print(f\"Next word prediction: {predicted_word}\")\n"
      ],
      "id": "c1b354ca"
    },
    {
      "cell_type": "markdown",
      "id": "7784becb",
      "metadata": {
        "id": "7784becb"
      },
      "source": [
        "\n",
        "## Conclusion\n",
        "\n",
        "In this notebook, we have covered the basics of implementing a language model using Sentence Transformers. We have shown how to encode sentences into embeddings, find similar sentences using cosine similarity, and cluster sentences using K-Means clustering. Sentence Transformers provide a powerful and flexible way to work with sentence embeddings for various NLP tasks.\n",
        "\n",
        "You can further explore Sentence Transformers by trying out different models, tweaking hyperparameters, and applying these techniques to your specific use cases. Happy coding!\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c2ohVsCEAROX"
      },
      "id": "c2ohVsCEAROX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}